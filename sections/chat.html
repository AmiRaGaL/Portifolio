<!-- <section id="chat" class="py-5" data-aos="fade-up">
  <div class="container">
    <h2 class="text-center text-primary mb-4">Ask My AI</h2>

    <div class="form-group">
      <label for="chat-prompt" class="sr-only">Prompt</label>
      <textarea id="chat-prompt" class="form-control" rows="3" placeholder="Ask about my projects, experience, or tech stack..."></textarea>
    </div>

    <div class="d-flex align-items-center gap-2">
      <select id="chat-model" class="custom-select" style="max-width: 320px;">
        <option value="">Default model</option>
        <option value="llama-3.1-70b-versatile">Llama 3.1 70B (versatile)</option>
        <option value="llama-3.1-8b-instant">Llama 3.1 8B (instant)</option>
      </select>
      <button id="chat-send" class="btn btn-primary ml-2">Ask</button>
    </div>

    <pre id="chat-answer" class="mt-3 p-3 border rounded" style="white-space:pre-wrap; min-height:120px;"></pre>
  </div>
</section> -->

<section id="chat" class="py-5" data-aos="fade-up">
  <div class="container">
    <h2 class="text-center text-primary mb-4">
      Ask My AI <small class="text-muted">(In Progress)</small>
    </h2>
    <p class="text-center text-muted mb-4">
      This experimental chat uses the default model while the fine-tuned version is in development.
    </p>

    <div class="form-group">
      <textarea id="chat-prompt" class="form-control" rows="3"
        placeholder="Ask about my projects, experience, or tech stack..."></textarea>
    </div>

    <div class="text-center">
      <button id="chat-send" class="btn btn-primary mt-2">Ask</button>
    </div>

    <pre id="chat-answer" class="mt-4 p-3 border rounded bg-light"
      style="white-space: pre-wrap; min-height: 100px;"></pre>
  </div>
</section>
